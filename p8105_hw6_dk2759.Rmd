---
title: "p8105_hw6_dk2759"
author: "Darwin Keung"
date: "11/25/2018"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
set.seed(1)
```

http://p8105.com/homework_6.html

-------
Homework 6
Context
This assignment reinforces ideas in Linear Models.

## Problem 1

The _Washington Post_ has gathered data on homicides in 50 large U.S. cities and made the data available through a GitHub repository [here](https://github.com/washingtonpost/data-homicides). You can read their accompanying article [here](https://www.washingtonpost.com/graphics/2018/investigations/where-murders-go-unsolved/). 

---------

#### Data import and cleaning

```{r import}
homicide_df = read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(city_state = str_c(city, ",", " ", state), 
         resolved = as.numeric(disposition == "Closed by arrest"), 
         victim_age = as.numeric(victim_age),
         victim_race = ifelse(victim_race == "White", "White", "Non-White"), 
         victim_race = fct_relevel(victim_race, "White")) %>% 
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"))) %>% 
  select(city_state, resolved, victim_age, victim_race, victim_sex)
```

The homicide dataset contains data collected from 50 big US cities over the a decade. It has `r nrow(homicide_df)` rows and `r ncol(homicide_df)` columns. Created city_state variable (e.g. “Baltimore, MD”), and a binary variable indicating whether the homicide is solved. Omitted cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. Also omitted Tulsa, AL – this is a data entry mistake. Modified victim_race to have categories white and non-white, with white as the reference category. victim_age is numeric.
The variables also include a unique id, report date, first and last names of victims, age, sex, race, location (city, state, lat, long), and disposition. 

### glm Baltimore

For the city of Baltimore, MD, use the `glm` function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race (as just defined) as predictors.
```{r Baltimore_glm}
fit_logr_baltimore = 
  homicide_df %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(resolved ~ victim_age + victim_race + victim_sex, 
      data = ., 
      family = binomial())
fit_logr_baltimore %>% 
  broom::tidy() %>% 
  janitor::clean_names() %>% 
  filter(term == "victim_raceNon-White") %>% 
  mutate(OR = exp(estimate), 
         lower_95ci = exp(estimate - 1.96*std_error), 
         upper_95ci = exp(estimate + 1.96*std_error)) %>%
  select(OR, lower_95ci, upper_95ci) %>% 
  knitr::kable(digits = 3)
```

The adjusted odd ratio of resolving the homicide case for non-white victims compared to white victims after adjusting for age and sex are 0.441 (95% CI: 0.313, 0.620).

### glm for each city

Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.

```{r log_regression_cities}
fit_logr_cities = homicide_df %>% 
  group_by(city_state) %>%
  nest() %>% 
  mutate(models = map(.x = data, 
                      ~ glm(resolved ~ victim_sex + victim_race + victim_age, 
                            data = .x,
                            family = binomial)),
         models = map(models, broom::tidy)) %>% 
  select(-data) %>% 
  unnest() %>%
  janitor::clean_names() %>% 
  filter(term == "victim_raceNon-White") %>%
  mutate(OR = exp(estimate), 
         lower_95ci = exp(estimate - 1.96*std_error), 
         upper_95ci = exp(estimate + 1.96*std_error)) %>%
  select(city_state, OR, lower_95ci, upper_95ci)
```

Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

```{r plot_cities}
fit_logr_cities = fit_logr_cities %>% 
  arrange(-desc(OR)) %>% 
  mutate(city_state = fct_inorder(city_state))
  
ggplot(fit_logr_cities, aes(x = city_state, y = OR )) + 
  geom_point() + 
  geom_errorbar(aes(ymin = lower_95ci, ymax = upper_95ci)) + 
  geom_hline(aes(yintercept = 1.00), linetype = "dashed", color = "green") +
  coord_flip() +
  theme(text = element_text(size = 9)) +
  labs(
    y = "Estimated Odds Ratio (95% Confidence interval)",
    x = "Location",
    title = "Estimated Odds Ratios of Resolved Homicides for Non-Whites compared to Whites Adjusted for Age and Sex by City"
  )
```

Most of the cities have an OR that crosses 1 which means there is no statistical significance for unsolved crime for non-whites vs whites. However for cities that have a OR less than 1, the likelihood of a non-white victims homicide being resolved is statistically less likely than a white victims case (see Boston, Omaha, Oakland as the 3 least likely cities). Tampa has the highest OR, Los Vegas and Oklahoma City have the highest ORs which a CI under 1.

## Problem 2

In this problem, you will analyze data gathered to understand the effects of several variables on a child’s birthweight. This dataset, available [here](http://p8105.com/data/birthweight.csv) consists of roughly 4000 children.

```{r import_bwt}
birthweight_df = read_csv("http://p8105.com/data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
    mutate(
      babysex = as.factor(babysex),
      frace = as.factor(frace),
      mrace = as.factor(mrace),
      malform = as.factor(malform))
#any missing?
filter_all(birthweight_df, any_vars(is.na(.)))
sum(is.na(birthweight_df))
## no missing data.
```

Hypothesis: baby's birthweight is associated with `menarche` mother’s age at menarche (years) 
Adjust for: baby's sex, mom's age, mom's race, mom's weight gain, mom's bmi prepregnancy, gestational age and average number of cigarettes smoked per day during pregnancy.

Use linear regression since the outcome of birthweight is continous. 

### Modeling my fit
```{r model 1}
model_1 = lm(bwt ~ gaweeks + babysex + momage + mrace + wtgain + ppbmi + smoken, data = birthweight_df)

model_1 %>% 
  broom::tidy() 
```

Plot model 1 residuals against fitted values – use add_predictions and add_residuals in making this plot.

```{r model 1 plot}
birthweight_df %>% 
  modelr::add_predictions(model_1) %>% 
  modelr::add_residuals(model_1) %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point() +
  labs(x = "Predicted value", 
       y = "Residual")
```

### Compare model to two others:

Using two other models to cross validate my own prediction model.
One using length at birth and gestational age as predictors (main effects only)

```{r model 2}
length_age_fit = lm(bwt ~ blength + gaweeks, data = birthweight_df)
length_age_fit %>% 
  broom::tidy()
```

One using head circumference, length, sex, and all interactions (including the three-way interaction)

```{r model 3}
hc_length_sex_fit = lm(bwt ~ bhead * blength * babysex, data = birthweight_df)
hc_length_sex_fit %>% 
  broom::tidy()
```

Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

## Cross Validation

Constructing training/testing splits
```{r cross validation}
cv_df =
  crossv_mc(birthweight_df, 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))
```

Fit models, get RMSEs

```{r}
cv_df = 
  cv_df %>% 
  mutate(length_age_fit =    map(train, ~ lm(bwt ~ blength + gaweeks, data = .x)),
         hc_length_sex_fit = map(train, ~ lm(bwt ~ bhead * blength * babysex, data = .x)),
         model_1 = map(train, ~ lm(bwt ~ gaweeks + babysex + momage + mrace + wtgain + ppbmi + smoken, data = .x))) %>% 
  mutate(rmse_length_age_fit = map2_dbl(length_age_fit, test, ~rmse(model = .x, data = .y)),
         rmse_hc_length_sex_fit = map2_dbl(hc_length_sex_fit, test, ~rmse(model = .x, data = .y)),
         rmse_model_1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)))
```

Distribution of RMSE values for each candidate model.

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() + 
  labs(
    x = "Model", 
    y = "RMSE", 
    title = "Distribution of RMSE values for each candidate Birthweight Distribution model"
  ) 
```

Plot Comments: Based on the distributions of RMSE it appears my predictive model has a lot more error than the other models. The best model of the three is the three way interaction using head circumference, length, sex variables.  
